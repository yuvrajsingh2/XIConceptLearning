{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.icsn as icsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change working directory to this path\n",
    "# C:\\Users\\yuviu\\Desktop\\Uni Work\\Thesis\\XIConceptLearning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "os.chdir(r'C:\\Users\\yuviu\\Desktop\\Uni Work\\Thesis\\XIConceptLearning')\n",
    "\n",
    "\n",
    "def get_dataloader(config):\n",
    "    print(f\"Getting dataloader for {config['dataset']}\")\n",
    "    dataset = load_data(config)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=config['batch_size'],\n",
    "                                       shuffle=True, num_workers=config['n_workers'], pin_memory=True)\n",
    "\n",
    "def load_data(config):\n",
    "    print('Loading data...')\n",
    "    print('Dataset: {}'.format(config['dataset']))\n",
    "    # dataloader setup\n",
    "    if config['dataset'] == 'ecr':\n",
    "        dataset = ECR_PairswithTest(config['data_dir'], attrs='')\n",
    "        config['img_shape'] = (3, 64, 64)\n",
    "        return dataset\n",
    "    elif config['dataset'] == 'ecr_spot':\n",
    "        dataset = ECR_PairswithTest(config['data_dir'],\n",
    "                                            attrs='_spot')\n",
    "        config['img_shape'] = (3, 64, 64)\n",
    "        return dataset\n",
    "    elif config['dataset'] == 'ecr_nospot':\n",
    "        dataset = ECR_PairswithTest(config['data_dir'],\n",
    "                                            attrs='_nospot')\n",
    "        config['img_shape'] = (3, 64, 64)\n",
    "        return dataset\n",
    "    elif config['dataset'] == 'dsprites':\n",
    "        dataset = DSpritesDataset(config['data_dir'], mode=config.get('mode', 'train'))\n",
    "        config['img_shape'] = (1, 64, 64)\n",
    "        return dataset\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Select valid dataset please')\n",
    "\n",
    "\n",
    "def get_test_set(data_loader, config):\n",
    "\n",
    "    x = data_loader.dataset.test_data\n",
    "    y = data_loader.dataset.test_labels.tolist()\n",
    "    y = [sample[0] for sample in y]\n",
    "    y_set = np.unique(y, axis=0).tolist()\n",
    "    x_set = []\n",
    "    for u in y_set:\n",
    "        x_set.append(np.moveaxis(x[y.index(u)][0], (0, 1, 2), (1, 2, 0)))\n",
    "    x_set = torch.Tensor(x_set)\n",
    "    x_set = x_set.to(config['device'])\n",
    "\n",
    "    y_set = torch.tensor(y_set)\n",
    "    return x_set, y_set\n",
    "\n",
    "\n",
    "class ECR_PairswithTest(Dataset):\n",
    "    def __init__(self, root, attrs, mode='train', single=False):\n",
    "        self.root = root\n",
    "        self.single_imgs = single\n",
    "        assert os.path.exists(root), 'Path {} does not exist'.format(root)\n",
    "\n",
    "        print(\"Loading \" + os.path.sep.join([root, f\"train_ecr{attrs}_pairs.npy\"]))\n",
    "\n",
    "        self.train_data_path = os.path.sep.join([root, mode, f\"{mode}_ecr{attrs}_pairs.npy\"])\n",
    "        self.test_data_path = os.path.sep.join([root, \"test\", f\"test_ecr{attrs}_pairs.npy\"])\n",
    "        self.train_labels_path = os.path.sep.join([root, mode, f\"{mode}_ecr{attrs}_labels_pairs.pkl\"])\n",
    "        self.test_labels_path = os.path.sep.join([root, \"test\", f\"test_ecr{attrs}_labels_pairs.pkl\"])\n",
    "\n",
    "        self.train_data = np.load(self.train_data_path, allow_pickle=True)\n",
    "        self.test_data = np.load(self.test_data_path, allow_pickle=True)\n",
    "\n",
    "        self.train_data = (self.train_data - self.train_data.min()) / (self.train_data.max() - self.train_data.min())\n",
    "        self.test_data = (self.test_data - self.test_data.min()) / (self.test_data.max() - self.test_data.min())\n",
    "\n",
    "        with open(self.train_labels_path, 'rb') as f:\n",
    "            labels_dict = pickle.load(f)\n",
    "            self.train_labels = labels_dict['labels_one_hot']\n",
    "            self.train_labels_as_id = labels_dict['labels']\n",
    "            try:\n",
    "                self.shared_labels = labels_dict['shared_labels']\n",
    "            except:\n",
    "                self.shared_labels = None\n",
    "        with open(self.test_labels_path, 'rb') as f:\n",
    "            labels_dict = pickle.load(f)\n",
    "            self.test_labels = labels_dict['labels_one_hot']\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imgs = self.train_data[index]\n",
    "\n",
    "        labels_one_hot = self.train_labels[index]\n",
    "        labels_ids = self.train_labels_as_id[index]\n",
    "\n",
    "        # compute which category is shared unless it was precomputed\n",
    "        if self.shared_labels is not None:\n",
    "            shared_labels = self.shared_labels[index].astype(np.bool_)\n",
    "        else:\n",
    "            shared_labels = (labels_ids[0] == labels_ids[1])\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        # transform the positive negative samples\n",
    "        img0 = transform(np.uint8(imgs[0]*255)).float()\n",
    "        img1 = transform(np.uint8(imgs[1]*255)).float()\n",
    "        # img_size = tuple(img0.shape[-2:])\n",
    "\n",
    "        if self.single_imgs:\n",
    "            return torch.cat((img0, img1), dim=0), torch.cat((labels_one_hot[0], labels_one_hot[1]), dim=0), \\\n",
    "                   torch.cat((labels_ids[0], labels_ids[1]), dim=0)\n",
    "        else:\n",
    "            return (img0, img1), (labels_one_hot[0], labels_one_hot[1]), (labels_ids[0], labels_ids[1]), shared_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "    \n",
    "class DSpritesDataset(Dataset):\n",
    "    def __init__(self, root, mode='train'):\n",
    "        self.root = root\n",
    "        assert os.path.exists(root), 'Path {} does not exist'.format(root)\n",
    "\n",
    "        with np.load(f'{self.root}/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz', allow_pickle=True, encoding='latin1') as data:\n",
    "            self.imgs = data['imgs']\n",
    "            self.latents_values = data['latents_values']\n",
    "            self.latents_classes = data['latents_classes']\n",
    "        # split the dataset into train and test sets\n",
    "        if mode == 'train':\n",
    "            self.imgs = self.imgs[:60000]  # first 60000 images as train set\n",
    "            self.latents_values = self.latents_values[:60000]\n",
    "        else:\n",
    "            self.imgs = self.imgs[60000:]  # remaining images as test set\n",
    "            self.latents_values = self.latents_values[60000:]\n",
    "\n",
    "        self.imgs = self.imgs[:, np.newaxis, :, :]  # add an extra dimension for the single channel (grayscale)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        img = img.astype(np.float32) / 255.0  # normalize pixel values to [0, 1]\n",
    "        img = torch.from_numpy(img)\n",
    "\n",
    "        latents = self.latents_values[index]\n",
    "        latents = torch.from_numpy(latents)\n",
    "\n",
    "        return img, latents\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "from utils import set_seed, makedirs\n",
    "\n",
    "\n",
    "# parse train options\n",
    "def _get_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--device', type=str, default='cuda', help='device to be used')\n",
    "    parser.add_argument('--device-ids', type=int, nargs='+', default=[0], help='device to be used')\n",
    "\n",
    "    # parser.add_argument('--learn', type=str, required=True, help='unsup, weakly or sup')\n",
    "\n",
    "    parser.add_argument('--save-step', type=int, default=50, help='save model every # steps')\n",
    "    parser.add_argument('--print-step', type=int, default=10, help='print metrics every # steps')\n",
    "    parser.add_argument('--display-step', type=int, default=1,\n",
    "                        help='track metrics and iamges on tensorboard every # steps')\n",
    "\n",
    "    # parser.add_argument('--lambda-recon-z', type=float, default=0., help='lambda for z recon loss')\n",
    "    parser.add_argument('--lambda-recon-proto', type=float, default=1.,\n",
    "                        help='lambda for agg prototype recon loss')\n",
    "    parser.add_argument('--lambda-rr', type=float, default=1.,\n",
    "                        help='lambda for rigth reason mse loss')\n",
    "    parser.add_argument('--train-protos', action='store_true', help='should the prototype embedding weights be updated '\n",
    "                                                                    'too?')\n",
    "    parser.add_argument('--freeze-enc', action='store_true', help='should the encoder be further finetuned or not')\n",
    "\n",
    "    parser.add_argument('-lr', '--learning-rate', type=float, default=1e-3, help='learning rate')\n",
    "    parser.add_argument('--lr-scheduler', action='store_true', help='use learning rate scheduler')\n",
    "    parser.add_argument('--lr-scheduler-warmup-steps', type=int, default=0,\n",
    "                        help='learning rate scheduler warmup steps')\n",
    "    parser.add_argument('-bs', '--batch-size', type=int, default=500, help='batch size, for paired training this is '\n",
    "                                                                           'the batch size of pairs, so in the end you '\n",
    "                                                                           'have 2xbs')\n",
    "    parser.add_argument('-e', '--epochs', type=int, default=500, help='Number of epochs to train for')\n",
    "    parser.add_argument('--n-workers', type=int, default=1, help='workers to load data')\n",
    "\n",
    "    parser.add_argument('-pv', '--prototype-vectors', type=int , nargs='+', default=[2, 3],\n",
    "                        help='List of number of prototype vectors per category [#p1, #p2, ...]')\n",
    "    parser.add_argument('--n-protos', type=int, default=2,\n",
    "                        help='number of classes per categorical variable, i.e. number of prototypes per group')\n",
    "    parser.add_argument('--proto-dim', type=int, default=32, help='dimensions of each prototype')\n",
    "    parser.add_argument('--extra-mlp-dim', type=int, default=4, help='dimensions of extra mlp')\n",
    "    parser.add_argument('--multiheads', action='store_true',\n",
    "                        help='should multiple mlp heads be used each for one category??')\n",
    "\n",
    "    parser.add_argument('--lin-enc-size', type=int, default=512, help='latent dimensions')\n",
    "    parser.add_argument('--temperature', type=float, default=1., help='temperature of gumbel softmax')\n",
    "\n",
    "    parser.add_argument('--exp-name', type=str, default='', help='experiment name')\n",
    "    parser.add_argument('--results-dir', type=str, default='results', help='results directory')\n",
    "    parser.add_argument('--model-dir', type=str, default='states', help='model directory')\n",
    "    parser.add_argument('--img-dir', type=str, default='imgs', help='image\\plot directory')\n",
    "    parser.add_argument('-dd', '--data-dir', type=str, default='Data/ECR', help='data directory')\n",
    "\n",
    "    parser.add_argument('-s', '--seed', type=int, default=42, help='seed')\n",
    "\n",
    "    parser.add_argument('-d', '--dataset', type=str, default='toycolor',\n",
    "                        help=\"'toycolor' or 'mnist' or 'toycolorshape' or 'toyshapesize' or 'toycolorshapesize'\")\n",
    "    parser.add_argument('--initials', type=str, required=False,\n",
    "                        help=\"Your initials\")\n",
    "    parser.add_argument('--fpath-load-pretrained', type=str, default=None,\n",
    "                        help='specify the fpath to the pretrained model')\n",
    "    parser.add_argument('--ckpt-fp', type=str, default=None,\n",
    "                        help='file path to ckpt file from which to continue training')\n",
    "    parser.add_argument('--test', action='store_true', help='should we just test?')\n",
    "    parser.add_argument('--wrong-protos', type=int, nargs='+', action='append', default=None,\n",
    "                        help='List of list of prototypes to ignore, e.g. 0, 2 for the first group. Please repeat the '\n",
    "                             'args for each further group, e.g. --wrong-protos 0 2 --wrong-protos 2 4 for a final '\n",
    "                             'list[[0,2], [2,4]]' )\n",
    "    parser.add_argument('--pent-id', type=int, default=None, help='which prototype should encode the pentagon shape?')\n",
    "    parser.add_argument('--circle-id', type=int, default=None, help='which prototype should encode the circle shape?')\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "def parse_args(argv):\n",
    "    \"\"\"Parses arguments passed from the console as, e.g.\n",
    "    'python ptt/main.py --epochs 3' \"\"\"\n",
    "\n",
    "    parser = _get_parser()\n",
    "    args = parser.parse_args(argv)\n",
    "\n",
    "    #args.prototype_vectors = [int(n) for n in args.prototype_vectors[0].split(',')]\n",
    "    # args.n_prototype_groups = len(args.prototype_vectors)\n",
    "    if args.exp_name == '':\n",
    "        args.exp_name = 'seed' + str(args.seed) + '_' \\\n",
    "                        + 'protos' + str(args.prototype_vectors) + '_' + \\\n",
    "                        str(datetime.datetime.now()).replace(' ', '_').replace(':', '-').split('.')[0]\n",
    "\n",
    "    args.results_dir = os.path.join(args.results_dir, args.exp_name)\n",
    "    args.model_dir = os.path.join(args.results_dir, args.model_dir)\n",
    "    args.img_dir = os.path.join(args.results_dir, args.img_dir)\n",
    "    makedirs(args.model_dir)\n",
    "    makedirs(args.img_dir)\n",
    "\n",
    "    # set seed for all random processes\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    args.device = str(\n",
    "        args.device + ':' + str(args.device_ids[0]) if torch.cuda.is_available() and args.device == \"cuda\" else \"cpu\")\n",
    "    device_name = str(torch.cuda.get_device_name(args.device) if args.device == \"cuda\" else args.device)\n",
    "    print('Device name: {}'.format(device_name))\n",
    "\n",
    "    args.n_groups = len(args.prototype_vectors)\n",
    "\n",
    "    # turn list of list into one list with cumulated ids, e.g. [[0, 2], [1, 3]] --> [0, 2, 7, 9] for two groups\n",
    "    # of 6 prototype vectors\n",
    "    if args.wrong_protos is not None:\n",
    "        tmp = []\n",
    "        pv_cumsum = np.insert(np.cumsum(args.prototype_vectors), 0, 0)\n",
    "        for i in range(len(args.prototype_vectors)):\n",
    "            tmp.extend(list((args.wrong_protos[i] + pv_cumsum[i]).astype(int)))\n",
    "        args.wrong_protos = [int(elem) for elem in tmp]\n",
    "\n",
    "    with open(os.path.join(args.results_dir, 'args.json'), 'w') as json_file:\n",
    "        json.dump(vars(args), json_file, indent=2)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def parse_args_as_dict(argv):\n",
    "    \"\"\"Parses arguments passed from the console and returns a dictionary \"\"\"\n",
    "    return vars(parse_args(argv))\n",
    "\n",
    "\n",
    "def parse_dict_as_args(dictionary):\n",
    "    \"\"\"Parses arguments given in a dictionary form\"\"\"\n",
    "    argv = []\n",
    "    for key, value in dictionary.items():\n",
    "        if isinstance(value, bool):\n",
    "            if value:\n",
    "                argv.append('--' + key)\n",
    "        else:\n",
    "            argv.append('--' + key)\n",
    "            argv.append(str(value))\n",
    "    return parse_args(argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: cuda:0\n"
     ]
    }
   ],
   "source": [
    "config = parse_args_as_dict(['--initials', 'test', \n",
    "                             '-dd', 'Data/dsprites',\n",
    "                             '-d', 'dsprites'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataloader for dsprites\n",
      "Loading data...\n",
      "Dataset: dsprites\n"
     ]
    }
   ],
   "source": [
    "_data_loader = get_dataloader(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: cuda:0\n",
      "Getting dataloader for dsprites\n",
      "Loading data...\n",
      "Dataset: dsprites\n",
      "Images shape: torch.Size([64, 1, 64, 64])\n",
      "Latents shape: torch.Size([64, 6])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def test_dataloader():\n",
    "    config = parse_args_as_dict(['--initials', 'test', \n",
    "                                 '-dd', 'Data/dsprites',\n",
    "                                 '-d', 'dsprites',\n",
    "                                 '-bs', '64', \n",
    "                                 '--n-workers', '0'])\n",
    "\n",
    "    dataloader = get_dataloader(config)\n",
    "\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "dataloader = test_dataloader()\n",
    "# Load a batch of data\n",
    "data_iter = iter(dataloader)\n",
    "images, latents = next(data_iter)\n",
    "\n",
    "print(f'Images shape: {images.shape}')\n",
    "print(f'Latents shape: {latents.shape}')\n",
    "\n",
    "# Optionally, display an image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images[0].squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latents[0]: tensor([1.0000, 1.0000, 0.5000, 3.2221, 0.6129, 0.0000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(f'Latents[0]: {latents[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot shape: torch.Size([64, 6])\n",
      "One hot[0]: tensor([0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(f'One hot shape: {one_hot.shape}')\n",
    "print(f'One hot[0]: {one_hot[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: cuda:0\n",
      "Getting dataloader for ecr\n",
      "Loading data...\n",
      "Dataset: ecr\n",
      "Loading Data/ECR\\train_ecr_pairs.npy\n"
     ]
    }
   ],
   "source": [
    "def test_dataloader_ecr():\n",
    "    config = parse_args_as_dict(['--initials', 'test', \n",
    "                                 '-dd', 'Data/ECR',\n",
    "                                 '-d', 'ecr',\n",
    "                                 '-bs', '64', \n",
    "                                 '--n-workers', '0'])\n",
    "\n",
    "    dataloader = get_dataloader(config)\n",
    "\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "dataloader_ecr = test_dataloader_ecr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgs[0].shape torch.Size([64, 3, 64, 64])\n",
      "imgs[1].shape torch.Size([64, 3, 64, 64])\n",
      "labels_one_hot[0].shape torch.Size([64, 10])\n",
      "labels_one_hot[1].shape torch.Size([64, 10])\n",
      "labels_id[0].shape torch.Size([64, 3])\n",
      "labels_id[1].shape torch.Size([64, 3])\n",
      "shared_labels.shape torch.Size([64, 3])\n"
     ]
    }
   ],
   "source": [
    "for i, (imgs, labels_one_hot, labels_id, shared_labels) in enumerate(dataloader_ecr):\n",
    "        # imgs is a list\n",
    "        print(f\"imgs[0].shape {imgs[0].shape}\")\n",
    "        print(f\"imgs[1].shape {imgs[1].shape}\")\n",
    "        print(f\"labels_one_hot[0].shape {labels_one_hot[0].shape}\")\n",
    "        print(f\"labels_one_hot[1].shape {labels_one_hot[1].shape}\")\n",
    "        print(f\"labels_id[0].shape {labels_id[0].shape}\")\n",
    "        print(f\"labels_id[1].shape {labels_id[1].shape}\")\n",
    "        print(f\"shared_labels.shape {shared_labels.shape}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a batch of data\n",
    "data_iter_ecr = iter(dataloader_ecr)\n",
    "images_ecr, labels_one_hot, labels_id, shared_labels = next(data_iter_ecr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len Images shape: 2\n",
      "Images shape: torch.Size([64, 3, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28127cf1580>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(f'len Images shape: {len(images_ecr)}')\n",
    "print(f'Images shape: {images_ecr[0].shape}')\n",
    "# plot using matplotlib\n",
    "# this image has 3 channels for RGB\n",
    "# images_ecr[0] has shape 64, 3, 64, 64\n",
    "# plot images_ecr with shape 64, 64, 3\n",
    "plt.imshow(images_ecr[1][0].permute(1, 2, 0))\n",
    "# paired image is images_ecr[1][0]\n",
    "plt.imshow(images_ecr[1][0].permute(1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 1., 1., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 1.]], dtype=torch.float64)\n",
      "tensor([[0, 2, 0],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 0],\n",
      "        [0, 3, 1],\n",
      "        [3, 2, 0],\n",
      "        [3, 1, 0],\n",
      "        [3, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [3, 2, 1],\n",
      "        [3, 2, 1],\n",
      "        [3, 2, 0],\n",
      "        [0, 1, 1],\n",
      "        [3, 2, 1],\n",
      "        [2, 2, 1],\n",
      "        [0, 2, 1],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 1],\n",
      "        [2, 3, 1],\n",
      "        [2, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [0, 2, 0],\n",
      "        [2, 2, 1],\n",
      "        [1, 3, 0],\n",
      "        [0, 3, 0],\n",
      "        [2, 3, 1],\n",
      "        [1, 3, 1],\n",
      "        [3, 3, 1],\n",
      "        [0, 1, 1],\n",
      "        [0, 1, 0],\n",
      "        [0, 3, 1],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [2, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [3, 1, 1],\n",
      "        [0, 1, 0],\n",
      "        [1, 3, 1],\n",
      "        [2, 2, 1],\n",
      "        [0, 0, 1],\n",
      "        [1, 0, 0],\n",
      "        [3, 3, 0],\n",
      "        [1, 3, 0],\n",
      "        [3, 0, 0],\n",
      "        [1, 2, 1],\n",
      "        [3, 0, 0],\n",
      "        [1, 2, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 1, 0],\n",
      "        [2, 3, 0],\n",
      "        [2, 3, 1],\n",
      "        [1, 0, 0],\n",
      "        [3, 3, 1],\n",
      "        [1, 3, 1],\n",
      "        [2, 0, 0],\n",
      "        [3, 1, 1],\n",
      "        [2, 1, 1],\n",
      "        [1, 2, 0],\n",
      "        [1, 0, 0],\n",
      "        [3, 3, 1],\n",
      "        [3, 2, 1],\n",
      "        [2, 3, 0],\n",
      "        [0, 0, 0],\n",
      "        [3, 3, 1]])\n"
     ]
    }
   ],
   "source": [
    "print((labels_one_hot[0]))\n",
    "print((labels_id[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 2, 0],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 0],\n",
      "        [0, 3, 1],\n",
      "        [3, 2, 0],\n",
      "        [3, 1, 0],\n",
      "        [3, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [3, 2, 1],\n",
      "        [3, 2, 1],\n",
      "        [3, 2, 0],\n",
      "        [0, 1, 1],\n",
      "        [3, 2, 1],\n",
      "        [2, 2, 1],\n",
      "        [0, 2, 1],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 1],\n",
      "        [2, 3, 1],\n",
      "        [2, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [0, 2, 0],\n",
      "        [2, 2, 1],\n",
      "        [1, 3, 0],\n",
      "        [0, 3, 0],\n",
      "        [2, 3, 1],\n",
      "        [1, 3, 1],\n",
      "        [3, 3, 1],\n",
      "        [0, 1, 1],\n",
      "        [0, 1, 0],\n",
      "        [0, 3, 1],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [2, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [3, 1, 1],\n",
      "        [0, 1, 0],\n",
      "        [1, 3, 1],\n",
      "        [2, 2, 1],\n",
      "        [0, 0, 1],\n",
      "        [1, 0, 0],\n",
      "        [3, 3, 0],\n",
      "        [1, 3, 0],\n",
      "        [3, 0, 0],\n",
      "        [1, 2, 1],\n",
      "        [3, 0, 0],\n",
      "        [1, 2, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 1, 0],\n",
      "        [2, 3, 0],\n",
      "        [2, 3, 1],\n",
      "        [1, 0, 0],\n",
      "        [3, 3, 1],\n",
      "        [1, 3, 1],\n",
      "        [2, 0, 0],\n",
      "        [3, 1, 1],\n",
      "        [2, 1, 1],\n",
      "        [1, 2, 0],\n",
      "        [1, 0, 0],\n",
      "        [3, 3, 1],\n",
      "        [3, 2, 1],\n",
      "        [2, 3, 0],\n",
      "        [0, 0, 0],\n",
      "        [3, 3, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(labels_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10, 10, figsize=(15, 15))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(images_ecr[i][0])\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Labels: \\n{train_labels['labels'][0][0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proto-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
