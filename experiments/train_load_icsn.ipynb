{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from BaseVAEs.models.disent.model.ae import EncoderConv64, DecoderConv64, AutoEncoder\n",
    "from BaseVAEs.models.disent.frameworks.vae.weaklysupervised import AdaVae, AdaCatVae\n",
    "from BaseVAEs.models.disent.frameworks.vae.unsupervised import BetaVae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import sys\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from rtpt.rtpt import RTPT\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BaseVAEs.utils_disent as utils\n",
    "import BaseVAEs.data as data\n",
    "from BaseVAEs.args import parse_args_as_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: cuda:0\n"
     ]
    }
   ],
   "source": [
    "sys_argv = [\n",
    "    \"--save-step\", \"20\",\n",
    "    \"--print-step\", \"1\",\n",
    "    \"--learning-rate\", \"0.0001\",\n",
    "    \"--batch-size\", \"128\",\n",
    "    \"--epochs\", \"2000\",\n",
    "    \"--exp-name\", \"unsup-betavae-0-ecr\",\n",
    "    \"--n-groups\", \"3\",\n",
    "    \"--n-protos\", \"6\",\n",
    "    \"--seed\", \"0\",\n",
    "    \"--dataset\", \"ecr\",\n",
    "    \"--initials\", \"WS\",\n",
    "    \"--lr-scheduler-warmup-steps\", \"1000\",\n",
    "    \"--data-dir\", \"Data\",\n",
    "    \"--results-dir\", \"experiments/BaseVAEs/runs/\",\n",
    "    \"--n-workers\", \"0\"\n",
    "]\n",
    "\n",
    "config = parse_args_as_dict(sys_argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "\tdevice: cuda:0\n",
      "\tdevice_ids: [0]\n",
      "\tsave_step: 20\n",
      "\tprint_step: 1\n",
      "\tdisplay_step: 1\n",
      "\tlambda_recon_proto: 1.0\n",
      "\ttrain_protos: False\n",
      "\tfreeze_enc: False\n",
      "\tlearning_rate: 0.0001\n",
      "\tlr_scheduler: False\n",
      "\tlr_scheduler_warmup_steps: 1000\n",
      "\tbatch_size: 128\n",
      "\tepochs: 2000\n",
      "\tn_workers: 0\n",
      "\tprototype_vectors: [2, 2]\n",
      "\tn_groups: 3\n",
      "\tn_protos: 6\n",
      "\tproto_dim: 32\n",
      "\textra_mlp_dim: 4\n",
      "\textra_softmax: False\n",
      "\tmultiheads: False\n",
      "\tbeta: 1.0\n",
      "\tlin_enc_size: 512\n",
      "\ttemperature: 1.0\n",
      "\texp_name: unsup-betavae-0-ecr\n",
      "\tresults_dir: experiments/BaseVAEs/runs/unsup-betavae-0-ecr\n",
      "\tmodel_dir: experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\states\n",
      "\timg_dir: experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\imgs\n",
      "\tdata_dir: Data\n",
      "\tseed: 0\n",
      "\tdataset: ecr\n",
      "\tinitials: WS\n",
      "\tfpath_load_pretrained: None\n",
      "\tckpt_fp: None\n",
      "\ttest: False\n",
      "\timg_shape: (3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# format print config\n",
    "print(\"Config:\")\n",
    "for k, v in config.items():\n",
    "    print(\"\\t{}: {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, data_loader, log_samples, optimizer, scheduler, writer, config):\n",
    "\n",
    "    rtpt = RTPT(name_initials=config['initials'], experiment_name='XIC_PrototypeDL', max_iterations=config['epochs'])\n",
    "    rtpt.start()\n",
    "\n",
    "    warmup_steps = 0\n",
    "\n",
    "    for e in range(0, config['epochs']):\n",
    "        max_iter = len(data_loader)\n",
    "        start = time.time()\n",
    "        loss_dict = dict(\n",
    "            {'z_recon_loss': 0, 'loss': 0, 'kld': 0, 'elbo': 0})\n",
    "\n",
    "        for i, batch in enumerate(data_loader):\n",
    "\n",
    "            # manual lr warmup\n",
    "            if warmup_steps < config['lr_scheduler_warmup_steps']:\n",
    "                learning_rate = config['learning_rate'] * (warmup_steps + 1) / config['lr_scheduler_warmup_steps']\n",
    "                optimizer.param_groups[0]['lr'] = learning_rate\n",
    "            warmup_steps += 1\n",
    "\n",
    "            imgs, labels_one_hot, labels_id, shared_labels = batch\n",
    "\n",
    "            imgs0 = imgs[0].to(config['device'])\n",
    "            imgs1 = imgs[1].to(config['device'])\n",
    "            imgs = torch.cat((imgs0, imgs1), dim=0)\n",
    "            # labels0_one_hot = labels_one_hot[0].to(config['device']).float()\n",
    "            # labels1_one_hot = labels_one_hot[1].to(config['device']).float()\n",
    "            # labels0_ids = labels_id[0].to(config['device']).float()\n",
    "            # labels1_ids = labels_id[1].to(config['device']).float()\n",
    "            # shared_labels = shared_labels.to(config['device'])\n",
    "\n",
    "            # from disent repo: x_targ is if augmentation is applied, otherwise x_targ is x\n",
    "            batch = {'x': (imgs,), 'x_targ': (imgs,)}\n",
    "            batch_loss_dict = model.compute_training_loss(batch, batch_idx=i)\n",
    "\n",
    "            loss, recon_loss, kl_reg_loss, kl_loss, elbo = batch_loss_dict['train_loss'], \\\n",
    "                                                           batch_loss_dict['recon_loss'], \\\n",
    "                                                           batch_loss_dict['kl_reg_loss'], \\\n",
    "                                                           batch_loss_dict['kl_loss'], \\\n",
    "                                                           batch_loss_dict['elbo']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if config['lr_scheduler'] and e > config['lr_scheduler_warmup_steps']:\n",
    "                scheduler.step()\n",
    "\n",
    "            loss_dict['z_recon_loss'] += recon_loss.item()\n",
    "            # loss_dict['proto_recon_loss'] += proto_recon_loss.item()\n",
    "            loss_dict['kld'] += kl_reg_loss.item()\n",
    "            loss_dict['loss'] += loss.item()\n",
    "            loss_dict['elbo'] += elbo.item()\n",
    "\n",
    "        for key in loss_dict.keys():\n",
    "            loss_dict[key] /= len(data_loader)\n",
    "\n",
    "        rtpt.step(subtitle=f'loss={loss_dict[\"loss\"]:2.2f}')\n",
    "\n",
    "        if (e + 1) % config['display_step'] == 0 or e == config['epochs'] - 1:\n",
    "            cur_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            writer.add_scalar(\"lr\", cur_lr, global_step=e)\n",
    "            for key in loss_dict.keys():\n",
    "                writer.add_scalar(f'train/{key}', loss_dict[key], global_step=e)\n",
    "\n",
    "        if (e + 1) % config['print_step'] == 0 or e == config['epochs'] - 1:\n",
    "            print(f'epoch {e} - loss {loss.item():2.4f} - time/epoch {(time.time() - start):2.2f}')\n",
    "            loss_summary = ''\n",
    "            for key in loss_dict.keys():\n",
    "                loss_summary += f'{key} {loss_dict[key]:2.4f} '\n",
    "            print(loss_summary)\n",
    "\n",
    "        if (e + 1) % config['save_step'] == 0 or e == config['epochs'] - 1 or e == 0:\n",
    "            state = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'ep': e,\n",
    "                'config': config\n",
    "            }\n",
    "            torch.save(state, os.path.join(config['model_dir'], '%05d.pth' % (e)))\n",
    "\n",
    "            # plot the individual prototypes of each group\n",
    "            # utils.plot_prototypes(model, writer, config, step=e)\n",
    "\n",
    "            # plot a few samples with proto recon\n",
    "            utils.plot_examples(log_samples, model, writer, config, step=e)\n",
    "\n",
    "            print(f'SAVED - epoch {e} - imgs @ {config[\"img_dir\"]} - model @ {config[\"model_dir\"]}')\n",
    "\n",
    "\n",
    "def main(config):\n",
    "\n",
    "    # get train data\n",
    "    _data_loader = data.get_dataloader(config)\n",
    "\n",
    "    # get test set samples\n",
    "    test_set = data.get_test_set(_data_loader, config)\n",
    "\n",
    "    # create tb writer\n",
    "    writer = SummaryWriter(log_dir=config['results_dir'])\n",
    "\n",
    "    # model setup\n",
    "    _model = BetaVae(make_optimizer_fn=lambda params: Adam(params, lr=1e-3),\n",
    "                 make_model_fn=lambda: AutoEncoder(\n",
    "                     encoder=EncoderConv64(x_shape=(3, 64, 64), z_size=config['n_groups'], z_multiplier=2),\n",
    "                     decoder=DecoderConv64(x_shape=(3, 64, 64), z_size=config['n_groups']),\n",
    "                 ),\n",
    "                 cfg=BetaVae.cfg(beta=4))\n",
    "\n",
    "    _model = _model.to(config['device'])\n",
    "\n",
    "    # optimizer setup\n",
    "    optimizer = torch.optim.Adam(_model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    # learning rate scheduler\n",
    "    scheduler = None\n",
    "    if config['lr_scheduler']:\n",
    "        # TODO: try LambdaLR\n",
    "        num_steps = len(_data_loader) * config['epochs']\n",
    "        num_steps += config['lr_scheduler_warmup_steps']\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_steps, eta_min=2e-5)\n",
    "\n",
    "    # start training\n",
    "    train(_model, _data_loader, test_set, optimizer, scheduler, writer, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataloader for ecr\n",
      "Loading data...\n",
      "Dataset: ecr\n",
      "root path: Data\\ECR\n",
      "root path: c:\\Users\\yuviu\\Desktop\\Uni Work\\Thesis\\XIConceptLearning\\experiments\\Data\\ECR\n",
      "Loading Data\\ECR\\train_ecr_pairs.npy\n",
      " Config num_workers: 0\n",
      "Loading test set...\n",
      "y_set shape: (32, 10)\n",
      "\ty_set: [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuviu\\Desktop\\Uni Work\\Thesis\\XIConceptLearning\\experiments\\BaseVAEs\\data.py:64: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  x_set = torch.Tensor(x_set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - loss 403.2914 - time/epoch 17.14\n",
      "z_recon_loss 454.2154 loss 454.2250 kld 0.0096 elbo -454.2178 \n",
      "SAVED - epoch 0 - imgs @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\imgs - model @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\states\n",
      "epoch 1 - loss 487.9590 - time/epoch 6.55\n",
      "z_recon_loss 455.9960 loss 456.0010 kld 0.0050 elbo -455.9972 \n",
      "epoch 2 - loss 413.6573 - time/epoch 5.81\n",
      "z_recon_loss 453.8225 loss 453.8234 kld 0.0009 elbo -453.8227 \n",
      "epoch 3 - loss 320.8172 - time/epoch 6.39\n",
      "z_recon_loss 450.7908 loss 450.7927 kld 0.0020 elbo -450.7912 \n",
      "epoch 4 - loss 513.6982 - time/epoch 6.13\n",
      "z_recon_loss 452.5975 loss 452.6313 kld 0.0338 elbo -452.6060 \n",
      "epoch 5 - loss 356.8102 - time/epoch 5.91\n",
      "z_recon_loss 441.8451 loss 442.1337 kld 0.2886 elbo -441.9172 \n",
      "epoch 6 - loss 501.0178 - time/epoch 6.03\n",
      "z_recon_loss 421.7423 loss 427.2255 kld 5.4832 elbo -423.1131 \n",
      "epoch 7 - loss 344.7471 - time/epoch 7.48\n",
      "z_recon_loss 391.8606 loss 401.1198 kld 9.2592 elbo -394.1754 \n",
      "epoch 8 - loss 398.3315 - time/epoch 5.95\n",
      "z_recon_loss 380.4000 loss 389.5298 kld 9.1297 elbo -382.6825 \n",
      "epoch 9 - loss 469.5906 - time/epoch 5.85\n",
      "z_recon_loss 371.5216 loss 380.1817 kld 8.6601 elbo -373.6866 \n",
      "epoch 10 - loss 427.9327 - time/epoch 5.72\n",
      "z_recon_loss 362.8999 loss 371.2053 kld 8.3055 elbo -364.9762 \n",
      "epoch 11 - loss 261.7889 - time/epoch 5.78\n",
      "z_recon_loss 354.8582 loss 362.8708 kld 8.0126 elbo -356.8613 \n",
      "epoch 12 - loss 502.9315 - time/epoch 5.93\n",
      "z_recon_loss 356.6365 loss 364.6542 kld 8.0177 elbo -358.6409 \n",
      "epoch 13 - loss 263.0023 - time/epoch 5.83\n",
      "z_recon_loss 344.4963 loss 352.9350 kld 8.4387 elbo -346.6060 \n",
      "epoch 14 - loss 283.4127 - time/epoch 5.88\n",
      "z_recon_loss 327.9188 loss 337.7977 kld 9.8789 elbo -330.3886 \n",
      "epoch 15 - loss 242.2633 - time/epoch 6.01\n",
      "z_recon_loss 269.1837 loss 285.9534 kld 16.7696 elbo -273.3761 \n",
      "epoch 16 - loss 299.6720 - time/epoch 6.57\n",
      "z_recon_loss 238.4029 loss 254.3346 kld 15.9317 elbo -242.3858 \n",
      "epoch 17 - loss 177.8031 - time/epoch 8.41\n",
      "z_recon_loss 215.8445 loss 231.4633 kld 15.6188 elbo -219.7492 \n",
      "epoch 18 - loss 205.6819 - time/epoch 6.78\n",
      "z_recon_loss 201.2917 loss 216.7741 kld 15.4824 elbo -205.1623 \n",
      "epoch 19 - loss 167.3350 - time/epoch 8.09\n",
      "z_recon_loss 187.9324 loss 203.4256 kld 15.4932 elbo -191.8057 \n",
      "SAVED - epoch 19 - imgs @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\imgs - model @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\states\n",
      "epoch 20 - loss 169.9205 - time/epoch 7.64\n",
      "z_recon_loss 179.0340 loss 194.2537 kld 15.2198 elbo -182.8389 \n",
      "epoch 21 - loss 172.9473 - time/epoch 5.99\n",
      "z_recon_loss 170.5088 loss 186.0529 kld 15.5440 elbo -174.3949 \n",
      "epoch 22 - loss 267.6182 - time/epoch 6.53\n",
      "z_recon_loss 164.9656 loss 180.5883 kld 15.6227 elbo -168.8713 \n",
      "epoch 23 - loss 165.0621 - time/epoch 6.57\n",
      "z_recon_loss 156.5152 loss 172.1862 kld 15.6709 elbo -160.4330 \n",
      "epoch 24 - loss 177.3806 - time/epoch 6.25\n",
      "z_recon_loss 150.1731 loss 166.0581 kld 15.8850 elbo -154.1444 \n",
      "epoch 25 - loss 159.0378 - time/epoch 6.36\n",
      "z_recon_loss 141.5395 loss 158.1799 kld 16.6404 elbo -145.6996 \n",
      "epoch 26 - loss 103.8949 - time/epoch 6.27\n",
      "z_recon_loss 122.9648 loss 141.7505 kld 18.7858 elbo -127.6612 \n",
      "epoch 27 - loss 103.6146 - time/epoch 6.13\n",
      "z_recon_loss 100.4515 loss 120.8387 kld 20.3872 elbo -105.5483 \n",
      "epoch 28 - loss 83.9390 - time/epoch 6.76\n",
      "z_recon_loss 91.5546 loss 111.6047 kld 20.0501 elbo -96.5671 \n",
      "epoch 29 - loss 120.2333 - time/epoch 7.23\n",
      "z_recon_loss 87.0249 loss 107.1523 kld 20.1273 elbo -92.0568 \n",
      "epoch 30 - loss 104.3678 - time/epoch 6.37\n",
      "z_recon_loss 84.7566 loss 104.6213 kld 19.8647 elbo -89.7228 \n",
      "epoch 31 - loss 89.3678 - time/epoch 6.03\n",
      "z_recon_loss 80.9148 loss 100.5651 kld 19.6503 elbo -85.8273 \n",
      "epoch 32 - loss 90.5702 - time/epoch 6.10\n",
      "z_recon_loss 78.9075 loss 98.4344 kld 19.5269 elbo -83.7892 \n",
      "epoch 33 - loss 90.6020 - time/epoch 6.01\n",
      "z_recon_loss 77.3074 loss 96.9482 kld 19.6408 elbo -82.2176 \n",
      "epoch 34 - loss 96.3630 - time/epoch 9.25\n",
      "z_recon_loss 75.7679 loss 95.3504 kld 19.5825 elbo -80.6635 \n",
      "epoch 35 - loss 83.0664 - time/epoch 6.56\n",
      "z_recon_loss 74.1641 loss 93.5651 kld 19.4011 elbo -79.0144 \n",
      "epoch 36 - loss 84.3363 - time/epoch 6.23\n",
      "z_recon_loss 72.8220 loss 92.1622 kld 19.3402 elbo -77.6571 \n",
      "epoch 37 - loss 88.3078 - time/epoch 6.13\n",
      "z_recon_loss 71.6336 loss 91.1859 kld 19.5523 elbo -76.5217 \n",
      "epoch 38 - loss 93.9865 - time/epoch 6.20\n",
      "z_recon_loss 70.8214 loss 90.2034 kld 19.3821 elbo -75.6669 \n",
      "epoch 39 - loss 79.0055 - time/epoch 6.20\n",
      "z_recon_loss 69.4023 loss 88.7737 kld 19.3714 elbo -74.2452 \n",
      "SAVED - epoch 39 - imgs @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\imgs - model @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\states\n",
      "epoch 40 - loss 86.1288 - time/epoch 6.62\n",
      "z_recon_loss 68.5328 loss 87.8649 kld 19.3321 elbo -73.3658 \n",
      "epoch 41 - loss 91.7043 - time/epoch 6.30\n",
      "z_recon_loss 67.7233 loss 87.1683 kld 19.4450 elbo -72.5846 \n",
      "epoch 42 - loss 82.1139 - time/epoch 6.32\n",
      "z_recon_loss 66.6316 loss 85.9321 kld 19.3005 elbo -71.4567 \n",
      "epoch 43 - loss 84.9473 - time/epoch 6.02\n",
      "z_recon_loss 65.8737 loss 85.2016 kld 19.3278 elbo -70.7057 \n",
      "epoch 44 - loss 95.0890 - time/epoch 6.12\n",
      "z_recon_loss 65.7296 loss 85.0713 kld 19.3418 elbo -70.5650 \n",
      "epoch 45 - loss 89.1068 - time/epoch 5.96\n",
      "z_recon_loss 64.3103 loss 83.6665 kld 19.3562 elbo -69.1493 \n",
      "epoch 46 - loss 76.6086 - time/epoch 6.00\n",
      "z_recon_loss 63.3421 loss 82.5906 kld 19.2485 elbo -68.1542 \n",
      "epoch 47 - loss 81.6240 - time/epoch 6.15\n",
      "z_recon_loss 62.3587 loss 81.5937 kld 19.2351 elbo -67.1674 \n",
      "epoch 48 - loss 94.3809 - time/epoch 6.02\n",
      "z_recon_loss 62.3106 loss 81.6499 kld 19.3394 elbo -67.1454 \n",
      "epoch 49 - loss 78.7936 - time/epoch 6.21\n",
      "z_recon_loss 61.2174 loss 80.4783 kld 19.2609 elbo -66.0326 \n",
      "epoch 50 - loss 69.1201 - time/epoch 6.21\n",
      "z_recon_loss 60.5077 loss 79.8144 kld 19.3067 elbo -65.3344 \n",
      "epoch 51 - loss 73.1594 - time/epoch 6.07\n",
      "z_recon_loss 59.6947 loss 78.9600 kld 19.2653 elbo -64.5110 \n",
      "epoch 52 - loss 85.5909 - time/epoch 6.22\n",
      "z_recon_loss 59.4848 loss 78.9358 kld 19.4511 elbo -64.3475 \n",
      "epoch 53 - loss 77.1389 - time/epoch 6.28\n",
      "z_recon_loss 58.7891 loss 78.0652 kld 19.2761 elbo -63.6081 \n",
      "epoch 54 - loss 73.6931 - time/epoch 7.63\n",
      "z_recon_loss 58.0165 loss 77.3551 kld 19.3386 elbo -62.8511 \n",
      "epoch 55 - loss 72.2574 - time/epoch 6.18\n",
      "z_recon_loss 57.4562 loss 76.8207 kld 19.3645 elbo -62.2974 \n",
      "epoch 56 - loss 79.0659 - time/epoch 6.33\n",
      "z_recon_loss 56.8646 loss 76.2147 kld 19.3501 elbo -61.7021 \n",
      "epoch 57 - loss 75.9709 - time/epoch 6.51\n",
      "z_recon_loss 56.3678 loss 75.7555 kld 19.3877 elbo -61.2147 \n",
      "epoch 58 - loss 80.1950 - time/epoch 6.03\n",
      "z_recon_loss 56.2233 loss 75.5362 kld 19.3129 elbo -61.0515 \n",
      "epoch 59 - loss 85.6546 - time/epoch 6.14\n",
      "z_recon_loss 55.8122 loss 75.1618 kld 19.3496 elbo -60.6496 \n",
      "SAVED - epoch 59 - imgs @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\imgs - model @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\states\n",
      "epoch 60 - loss 78.0362 - time/epoch 6.32\n",
      "z_recon_loss 55.4043 loss 74.6963 kld 19.2920 elbo -60.2273 \n",
      "epoch 61 - loss 67.9811 - time/epoch 6.20\n",
      "z_recon_loss 54.3200 loss 73.6936 kld 19.3736 elbo -59.1634 \n",
      "epoch 62 - loss 72.1980 - time/epoch 6.18\n",
      "z_recon_loss 53.7891 loss 73.0689 kld 19.2798 elbo -58.6091 \n",
      "epoch 63 - loss 69.2957 - time/epoch 6.07\n",
      "z_recon_loss 53.2320 loss 72.6996 kld 19.4677 elbo -58.0989 \n",
      "epoch 64 - loss 61.3510 - time/epoch 6.26\n",
      "z_recon_loss 52.6620 loss 71.9336 kld 19.2715 elbo -57.4799 \n",
      "epoch 65 - loss 69.2059 - time/epoch 6.09\n",
      "z_recon_loss 52.0658 loss 71.3606 kld 19.2948 elbo -56.8895 \n",
      "epoch 66 - loss 63.0488 - time/epoch 6.01\n",
      "z_recon_loss 51.6454 loss 71.0166 kld 19.3712 elbo -56.4882 \n",
      "epoch 67 - loss 67.4805 - time/epoch 6.05\n",
      "z_recon_loss 51.1894 loss 70.5635 kld 19.3742 elbo -56.0329 \n",
      "epoch 68 - loss 59.9146 - time/epoch 6.22\n",
      "z_recon_loss 50.7961 loss 70.1647 kld 19.3687 elbo -55.6383 \n",
      "epoch 69 - loss 75.4810 - time/epoch 6.26\n",
      "z_recon_loss 50.4358 loss 69.9649 kld 19.5292 elbo -55.3180 \n",
      "epoch 70 - loss 71.5541 - time/epoch 6.01\n",
      "z_recon_loss 50.3329 loss 69.6565 kld 19.3236 elbo -55.1638 \n",
      "epoch 71 - loss 67.3496 - time/epoch 5.97\n",
      "z_recon_loss 49.4334 loss 68.9362 kld 19.5029 elbo -54.3091 \n",
      "epoch 72 - loss 68.6058 - time/epoch 6.09\n",
      "z_recon_loss 49.3446 loss 68.9699 kld 19.6253 elbo -54.2509 \n",
      "epoch 73 - loss 59.4865 - time/epoch 6.00\n",
      "z_recon_loss 48.8321 loss 68.2278 kld 19.3957 elbo -53.6810 \n",
      "epoch 74 - loss 78.1372 - time/epoch 6.39\n",
      "z_recon_loss 48.6722 loss 68.1199 kld 19.4477 elbo -53.5341 \n",
      "epoch 75 - loss 65.1974 - time/epoch 6.42\n",
      "z_recon_loss 47.9428 loss 67.4749 kld 19.5321 elbo -52.8258 \n",
      "epoch 76 - loss 65.8486 - time/epoch 4.30\n",
      "z_recon_loss 47.5391 loss 67.0132 kld 19.4741 elbo -52.4076 \n",
      "epoch 77 - loss 77.8651 - time/epoch 6.19\n",
      "z_recon_loss 47.4365 loss 66.6925 kld 19.2560 elbo -52.2505 \n",
      "epoch 78 - loss 66.9927 - time/epoch 6.10\n",
      "z_recon_loss 47.2756 loss 66.7442 kld 19.4687 elbo -52.1427 \n",
      "epoch 79 - loss 50.5978 - time/epoch 6.03\n",
      "z_recon_loss 46.0806 loss 65.4109 kld 19.3303 elbo -50.9132 \n",
      "SAVED - epoch 79 - imgs @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\imgs - model @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\states\n",
      "epoch 80 - loss 62.3629 - time/epoch 7.61\n",
      "z_recon_loss 46.1137 loss 65.5020 kld 19.3883 elbo -50.9608 \n",
      "epoch 81 - loss 67.1571 - time/epoch 6.15\n",
      "z_recon_loss 45.7531 loss 65.1627 kld 19.4096 elbo -50.6055 \n",
      "epoch 82 - loss 74.9361 - time/epoch 5.83\n",
      "z_recon_loss 46.1529 loss 65.5527 kld 19.3998 elbo -51.0028 \n",
      "epoch 83 - loss 57.5259 - time/epoch 6.03\n",
      "z_recon_loss 45.4141 loss 64.8470 kld 19.4329 elbo -50.2723 \n",
      "epoch 84 - loss 58.8415 - time/epoch 5.97\n",
      "z_recon_loss 44.7522 loss 64.0933 kld 19.3411 elbo -49.5874 \n",
      "epoch 85 - loss 77.3415 - time/epoch 6.34\n",
      "z_recon_loss 44.7035 loss 64.1633 kld 19.4598 elbo -49.5684 \n",
      "epoch 86 - loss 61.3721 - time/epoch 6.00\n",
      "z_recon_loss 44.4208 loss 63.7201 kld 19.2993 elbo -49.2456 \n",
      "epoch 87 - loss 56.0281 - time/epoch 6.02\n",
      "z_recon_loss 43.7905 loss 63.0999 kld 19.3093 elbo -48.6179 \n",
      "epoch 88 - loss 64.5924 - time/epoch 5.90\n",
      "z_recon_loss 43.5242 loss 62.8878 kld 19.3635 elbo -48.3651 \n",
      "epoch 89 - loss 64.5751 - time/epoch 5.98\n",
      "z_recon_loss 43.1841 loss 62.6262 kld 19.4421 elbo -48.0446 \n",
      "epoch 90 - loss 61.5753 - time/epoch 6.04\n",
      "z_recon_loss 43.3693 loss 62.8187 kld 19.4494 elbo -48.2316 \n",
      "epoch 91 - loss 69.1370 - time/epoch 9.11\n",
      "z_recon_loss 42.9262 loss 62.2925 kld 19.3663 elbo -47.7678 \n",
      "epoch 92 - loss 54.0157 - time/epoch 6.08\n",
      "z_recon_loss 42.0201 loss 61.4492 kld 19.4291 elbo -46.8774 \n",
      "epoch 93 - loss 62.5505 - time/epoch 6.12\n",
      "z_recon_loss 42.0929 loss 61.4081 kld 19.3151 elbo -46.9217 \n",
      "epoch 94 - loss 63.4758 - time/epoch 6.84\n",
      "z_recon_loss 42.1214 loss 61.3929 kld 19.2715 elbo -46.9393 \n",
      "epoch 95 - loss 62.4497 - time/epoch 6.26\n",
      "z_recon_loss 41.7114 loss 60.8997 kld 19.1884 elbo -46.5085 \n",
      "epoch 96 - loss 63.3343 - time/epoch 7.40\n",
      "z_recon_loss 41.7488 loss 61.3125 kld 19.5637 elbo -46.6397 \n",
      "epoch 97 - loss 61.4556 - time/epoch 6.24\n",
      "z_recon_loss 41.5394 loss 60.8986 kld 19.3592 elbo -46.3792 \n",
      "epoch 98 - loss 52.6487 - time/epoch 6.74\n",
      "z_recon_loss 40.9169 loss 60.2593 kld 19.3424 elbo -45.7525 \n",
      "epoch 99 - loss 64.8846 - time/epoch 6.76\n",
      "z_recon_loss 40.8002 loss 60.1152 kld 19.3151 elbo -45.6289 \n",
      "SAVED - epoch 99 - imgs @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\imgs - model @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\states\n",
      "epoch 100 - loss 52.9392 - time/epoch 7.17\n",
      "z_recon_loss 40.3979 loss 59.5763 kld 19.1784 elbo -45.1925 \n",
      "epoch 101 - loss 56.7334 - time/epoch 7.32\n",
      "z_recon_loss 40.1621 loss 59.5324 kld 19.3702 elbo -45.0047 \n",
      "epoch 102 - loss 53.7191 - time/epoch 7.33\n",
      "z_recon_loss 39.9542 loss 59.1901 kld 19.2359 elbo -44.7632 \n",
      "epoch 103 - loss 60.2529 - time/epoch 5.98\n",
      "z_recon_loss 39.9288 loss 59.1391 kld 19.2103 elbo -44.7314 \n",
      "epoch 104 - loss 65.8734 - time/epoch 5.74\n",
      "z_recon_loss 39.7401 loss 59.1424 kld 19.4023 elbo -44.5907 \n",
      "epoch 105 - loss 56.3798 - time/epoch 5.66\n",
      "z_recon_loss 39.4830 loss 58.7592 kld 19.2762 elbo -44.3021 \n",
      "epoch 106 - loss 63.0874 - time/epoch 5.42\n",
      "z_recon_loss 39.3894 loss 58.7151 kld 19.3257 elbo -44.2208 \n",
      "epoch 107 - loss 57.8376 - time/epoch 5.55\n",
      "z_recon_loss 39.2072 loss 58.4894 kld 19.2823 elbo -44.0277 \n",
      "epoch 108 - loss 54.7674 - time/epoch 6.02\n",
      "z_recon_loss 38.8417 loss 58.1030 kld 19.2613 elbo -43.6571 \n",
      "epoch 109 - loss 59.0523 - time/epoch 5.79\n",
      "z_recon_loss 38.7890 loss 57.9025 kld 19.1136 elbo -43.5674 \n",
      "epoch 110 - loss 51.1083 - time/epoch 6.20\n",
      "z_recon_loss 38.9128 loss 58.1641 kld 19.2513 elbo -43.7256 \n",
      "epoch 111 - loss 54.2142 - time/epoch 5.82\n",
      "z_recon_loss 38.1580 loss 57.3079 kld 19.1499 elbo -42.9455 \n",
      "epoch 112 - loss 60.3678 - time/epoch 5.74\n",
      "z_recon_loss 38.3527 loss 57.4099 kld 19.0571 elbo -43.1170 \n",
      "epoch 113 - loss 54.6619 - time/epoch 5.74\n",
      "z_recon_loss 38.3944 loss 57.5680 kld 19.1736 elbo -43.1878 \n",
      "epoch 114 - loss 59.8179 - time/epoch 5.70\n",
      "z_recon_loss 37.8791 loss 56.9602 kld 19.0811 elbo -42.6494 \n",
      "epoch 115 - loss 48.3792 - time/epoch 5.72\n",
      "z_recon_loss 37.6487 loss 56.9812 kld 19.3325 elbo -42.4818 \n",
      "epoch 116 - loss 53.9367 - time/epoch 5.86\n",
      "z_recon_loss 37.5204 loss 56.5639 kld 19.0434 elbo -42.2813 \n",
      "epoch 117 - loss 56.4096 - time/epoch 5.86\n",
      "z_recon_loss 37.6780 loss 56.9499 kld 19.2719 elbo -42.4960 \n",
      "epoch 118 - loss 71.4333 - time/epoch 5.68\n",
      "z_recon_loss 37.4634 loss 56.6829 kld 19.2196 elbo -42.2683 \n",
      "epoch 119 - loss 64.4850 - time/epoch 5.89\n",
      "z_recon_loss 37.6454 loss 56.7126 kld 19.0672 elbo -42.4122 \n",
      "SAVED - epoch 119 - imgs @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\imgs - model @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\states\n",
      "epoch 120 - loss 53.6633 - time/epoch 6.03\n",
      "z_recon_loss 36.9074 loss 56.0174 kld 19.1100 elbo -41.6849 \n",
      "epoch 121 - loss 58.4296 - time/epoch 5.79\n",
      "z_recon_loss 36.7898 loss 55.8840 kld 19.0941 elbo -41.5634 \n",
      "epoch 122 - loss 51.6429 - time/epoch 5.93\n",
      "z_recon_loss 36.4887 loss 55.5969 kld 19.1081 elbo -41.2658 \n",
      "epoch 123 - loss 57.0862 - time/epoch 5.74\n",
      "z_recon_loss 36.6476 loss 55.6163 kld 18.9688 elbo -41.3897 \n",
      "epoch 124 - loss 56.4133 - time/epoch 5.83\n",
      "z_recon_loss 36.4246 loss 55.4770 kld 19.0524 elbo -41.1877 \n",
      "epoch 125 - loss 55.4161 - time/epoch 5.71\n",
      "z_recon_loss 36.2567 loss 55.2804 kld 19.0237 elbo -41.0126 \n",
      "epoch 126 - loss 53.6133 - time/epoch 5.80\n",
      "z_recon_loss 36.8386 loss 55.9729 kld 19.1343 elbo -41.6222 \n",
      "epoch 127 - loss 55.5303 - time/epoch 5.87\n",
      "z_recon_loss 36.1141 loss 55.2203 kld 19.1061 elbo -40.8907 \n",
      "epoch 128 - loss 60.7488 - time/epoch 5.78\n",
      "z_recon_loss 36.4113 loss 55.4452 kld 19.0339 elbo -41.1698 \n",
      "epoch 129 - loss 66.8911 - time/epoch 5.64\n",
      "z_recon_loss 36.3674 loss 55.6678 kld 19.3004 elbo -41.1925 \n",
      "epoch 130 - loss 43.9641 - time/epoch 5.81\n",
      "z_recon_loss 35.5982 loss 54.7089 kld 19.1107 elbo -40.3759 \n",
      "epoch 131 - loss 53.5029 - time/epoch 5.64\n",
      "z_recon_loss 35.3922 loss 54.3529 kld 18.9607 elbo -40.1324 \n",
      "epoch 132 - loss 51.3310 - time/epoch 5.77\n",
      "z_recon_loss 35.4438 loss 54.4790 kld 19.0352 elbo -40.2026 \n",
      "epoch 133 - loss 50.0683 - time/epoch 6.26\n",
      "z_recon_loss 35.4236 loss 54.4773 kld 19.0538 elbo -40.1870 \n",
      "epoch 134 - loss 55.8895 - time/epoch 5.90\n",
      "z_recon_loss 35.2278 loss 54.1836 kld 18.9558 elbo -39.9667 \n",
      "epoch 135 - loss 60.6610 - time/epoch 5.67\n",
      "z_recon_loss 35.2426 loss 54.2958 kld 19.0532 elbo -40.0059 \n",
      "epoch 136 - loss 50.0080 - time/epoch 5.76\n",
      "z_recon_loss 34.9758 loss 53.9138 kld 18.9380 elbo -39.7103 \n",
      "epoch 137 - loss 59.1035 - time/epoch 5.66\n",
      "z_recon_loss 35.3604 loss 54.3886 kld 19.0282 elbo -40.1175 \n",
      "epoch 138 - loss 53.2638 - time/epoch 5.64\n",
      "z_recon_loss 34.7660 loss 53.8235 kld 19.0576 elbo -39.5303 \n",
      "epoch 139 - loss 49.0940 - time/epoch 6.03\n",
      "z_recon_loss 34.7036 loss 53.6432 kld 18.9396 elbo -39.4385 \n",
      "SAVED - epoch 139 - imgs @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\imgs - model @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\states\n",
      "epoch 140 - loss 49.3315 - time/epoch 6.03\n",
      "z_recon_loss 34.3776 loss 53.3178 kld 18.9403 elbo -39.1126 \n",
      "epoch 141 - loss 58.7718 - time/epoch 6.62\n",
      "z_recon_loss 34.4736 loss 53.4413 kld 18.9677 elbo -39.2155 \n",
      "epoch 142 - loss 53.4023 - time/epoch 9.18\n",
      "z_recon_loss 34.4066 loss 53.4171 kld 19.0104 elbo -39.1592 \n",
      "epoch 143 - loss 44.5159 - time/epoch 6.67\n",
      "z_recon_loss 33.9142 loss 52.8716 kld 18.9574 elbo -38.6535 \n",
      "epoch 144 - loss 46.9560 - time/epoch 6.28\n",
      "z_recon_loss 34.0979 loss 52.9983 kld 18.9004 elbo -38.8230 \n",
      "epoch 145 - loss 51.3394 - time/epoch 5.88\n",
      "z_recon_loss 34.0064 loss 52.9414 kld 18.9350 elbo -38.7401 \n",
      "epoch 146 - loss 45.3909 - time/epoch 5.98\n",
      "z_recon_loss 33.8406 loss 52.7521 kld 18.9115 elbo -38.5685 \n",
      "epoch 147 - loss 51.7136 - time/epoch 6.31\n",
      "z_recon_loss 33.8998 loss 52.8052 kld 18.9054 elbo -38.6261 \n",
      "epoch 148 - loss 47.1950 - time/epoch 6.70\n",
      "z_recon_loss 33.4966 loss 52.4077 kld 18.9111 elbo -38.2244 \n",
      "epoch 149 - loss 55.1250 - time/epoch 7.72\n",
      "z_recon_loss 33.7320 loss 52.6304 kld 18.8985 elbo -38.4566 \n",
      "epoch 150 - loss 51.7415 - time/epoch 7.81\n",
      "z_recon_loss 34.6651 loss 53.7757 kld 19.1106 elbo -39.4428 \n",
      "epoch 151 - loss 54.0209 - time/epoch 6.89\n",
      "z_recon_loss 33.6032 loss 52.4656 kld 18.8624 elbo -38.3188 \n",
      "epoch 152 - loss 58.6109 - time/epoch 6.60\n",
      "z_recon_loss 33.5665 loss 52.6224 kld 19.0560 elbo -38.3305 \n",
      "epoch 153 - loss 48.7129 - time/epoch 6.04\n",
      "z_recon_loss 33.3456 loss 52.2098 kld 18.8643 elbo -38.0616 \n",
      "epoch 154 - loss 46.9044 - time/epoch 6.10\n",
      "z_recon_loss 33.0735 loss 51.9530 kld 18.8795 elbo -37.7933 \n",
      "epoch 155 - loss 46.2051 - time/epoch 6.12\n",
      "z_recon_loss 33.0016 loss 51.9046 kld 18.9030 elbo -37.7273 \n",
      "epoch 156 - loss 57.2437 - time/epoch 6.35\n",
      "z_recon_loss 33.2213 loss 52.1606 kld 18.9393 elbo -37.9561 \n",
      "epoch 157 - loss 53.9990 - time/epoch 6.34\n",
      "z_recon_loss 33.0075 loss 52.1052 kld 19.0977 elbo -37.7819 \n",
      "epoch 158 - loss 56.4362 - time/epoch 7.76\n",
      "z_recon_loss 33.0886 loss 51.9084 kld 18.8199 elbo -37.7935 \n",
      "epoch 159 - loss 58.0468 - time/epoch 6.26\n",
      "z_recon_loss 32.9701 loss 51.9151 kld 18.9450 elbo -37.7064 \n",
      "SAVED - epoch 159 - imgs @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\imgs - model @ experiments/BaseVAEs/runs/unsup-betavae-0-ecr\\states\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yuviu\\Desktop\\Uni Work\\Thesis\\XIConceptLearning\\experiments\\load_icsn.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yuviu/Desktop/Uni%20Work/Thesis/XIConceptLearning/experiments/load_icsn.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m main(config\u001b[39m=\u001b[39;49mconfig)\n",
      "\u001b[1;32mc:\\Users\\yuviu\\Desktop\\Uni Work\\Thesis\\XIConceptLearning\\experiments\\load_icsn.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/yuviu/Desktop/Uni%20Work/Thesis/XIConceptLearning/experiments/load_icsn.ipynb#X13sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m     scheduler \u001b[39m=\u001b[39m lr_scheduler\u001b[39m.\u001b[39mCosineAnnealingLR(optimizer, T_max\u001b[39m=\u001b[39mnum_steps, eta_min\u001b[39m=\u001b[39m\u001b[39m2e-5\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/yuviu/Desktop/Uni%20Work/Thesis/XIConceptLearning/experiments/load_icsn.ipynb#X13sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m \u001b[39m# start training\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/yuviu/Desktop/Uni%20Work/Thesis/XIConceptLearning/experiments/load_icsn.ipynb#X13sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m train(_model, _data_loader, test_set, optimizer, scheduler, writer, config)\n",
      "\u001b[1;32mc:\\Users\\yuviu\\Desktop\\Uni Work\\Thesis\\XIConceptLearning\\experiments\\load_icsn.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuviu/Desktop/Uni%20Work/Thesis/XIConceptLearning/experiments/load_icsn.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuviu/Desktop/Uni%20Work/Thesis/XIConceptLearning/experiments/load_icsn.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuviu/Desktop/Uni%20Work/Thesis/XIConceptLearning/experiments/load_icsn.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     {\u001b[39m'\u001b[39m\u001b[39mz_recon_loss\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mkld\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39melbo\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m})\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yuviu/Desktop/Uni%20Work/Thesis/XIConceptLearning/experiments/load_icsn.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuviu/Desktop/Uni%20Work/Thesis/XIConceptLearning/experiments/load_icsn.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuviu/Desktop/Uni%20Work/Thesis/XIConceptLearning/experiments/load_icsn.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# manual lr warmup\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuviu/Desktop/Uni%20Work/Thesis/XIConceptLearning/experiments/load_icsn.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m warmup_steps \u001b[39m<\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mlr_scheduler_warmup_steps\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuviu/Desktop/Uni%20Work/Thesis/XIConceptLearning/experiments/load_icsn.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         learning_rate \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m (warmup_steps \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mlr_scheduler_warmup_steps\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\yuviu\\anaconda3\\envs\\proto-learning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\yuviu\\anaconda3\\envs\\proto-learning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\yuviu\\anaconda3\\envs\\proto-learning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\yuviu\\anaconda3\\envs\\proto-learning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\yuviu\\Desktop\\Uni Work\\Thesis\\XIConceptLearning\\experiments\\BaseVAEs\\data.py:124\u001b[0m, in \u001b[0;36mECR_PairswithTest.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m# transform the positive negative samples\u001b[39;00m\n\u001b[0;32m    123\u001b[0m img0 \u001b[39m=\u001b[39m transform(np\u001b[39m.\u001b[39muint8(imgs[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m255\u001b[39m))\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m--> 124\u001b[0m img1 \u001b[39m=\u001b[39m transform(np\u001b[39m.\u001b[39;49muint8(imgs[\u001b[39m1\u001b[39;49m]\u001b[39m*\u001b[39;49m\u001b[39m255\u001b[39;49m))\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m    125\u001b[0m \u001b[39m# img_size = tuple(img0.shape[-2:])\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingle_imgs:\n",
      "File \u001b[1;32mc:\\Users\\yuviu\\anaconda3\\envs\\proto-learning\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\yuviu\\anaconda3\\envs\\proto-learning\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32mc:\\Users\\yuviu\\anaconda3\\envs\\proto-learning\\lib\\site-packages\\torchvision\\transforms\\functional.py:170\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    169\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m img\n\u001b[1;32m--> 170\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mview(pic\u001b[39m.\u001b[39;49msize[\u001b[39m1\u001b[39;49m], pic\u001b[39m.\u001b[39;49msize[\u001b[39m0\u001b[39;49m], F_pil\u001b[39m.\u001b[39;49mget_image_num_channels(pic))\n\u001b[0;32m    171\u001b[0m \u001b[39m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m    172\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained(model, ckpt):\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "    model.proto_dict = ckpt['model_misc']['prototypes']\n",
    "    model.softmax_temp = ckpt['model_misc']['softmax_temp']\n",
    "    return model\n",
    "\n",
    "from ProtoLearning.models.icsn import iCSN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuviu\\Desktop\\Uni Work\\Thesis\\XIConceptLearning\n",
      "c:\\Users\\yuviu\\Desktop\\Uni Work\\Thesis\\XIConceptLearning\\experiments\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "# change to ../\n",
    "os.chdir('experiments')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proto-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
